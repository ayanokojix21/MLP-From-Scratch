{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "roovQWdUlU9e"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "E62pPsMhqVse",
        "outputId": "ef4f5870-98c9-431d-e458-0ecd271d6ebf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1eefd0c7-dfa6-4a91-9f7c-6bcb3c6a6eed\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1eefd0c7-dfa6-4a91-9f7c-6bcb3c6a6eed\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the Dataset\n",
        "!kaggle datasets download meemr5/indian-names-boys-girls\n",
        "!unzip indian-names-boys-girls.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldhZN6Z8qhxM",
        "outputId": "70fdbf2c-f6ff-45e0-90fa-5cfba6ae563b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/meemr5/indian-names-boys-girls\n",
            "License(s): CC0-1.0\n",
            "Downloading indian-names-boys-girls.zip to /content\n",
            "  0% 0.00/161k [00:00<?, ?B/s]\n",
            "100% 161k/161k [00:00<00:00, 400MB/s]\n",
            "Archive:  indian-names-boys-girls.zip\n",
            "  inflating: Names.txt               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading all the names\n",
        "names = open('Names.txt', 'r').read().lower().splitlines()\n",
        "print(len(names)) # Number of names in the Dataset\n",
        "print(max(len(n) for n in names)) # Max number of character in a name\n",
        "print(min(len(n) for n in names)) # Min Number of character in a name\n",
        "print(names[:5]) # First 5 names in the Dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvnc2K6UqqMR",
        "outputId": "3703638e-a04c-484d-a4ef-f7c2880fc0bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55691\n",
            "25\n",
            "2\n",
            "['aaban', 'aabharan', 'aabhas', 'aabhat', 'aabheer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Unneccessary Names from the Dataset\n",
        "names = [name for name in names if '-' not in name and '.' not in name and ' ' not in name]\n",
        "print(len(names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAl718gWsSdd",
        "outputId": "48febae3-25f7-4bf2-88fd-51a1cfec1840"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Vocabulary of Characters\n",
        "chars = sorted(set(list(''.join(names)))) # Unique characters in the Dataset\n",
        "print(len(chars)) # Length of those characters list\n",
        "char2idx = {s : i for i,s in enumerate(chars)} # mapping character to a particular index value\n",
        "char2idx['.'] = 0 # Unique Character which will behave as <START> and <END> TOKEN in the Dataset\n",
        "idx2char = {i : s for s,i in char2idx.items()} # Mapping each index to a particular character\n",
        "vocal_size = len(char2idx) # Vocabulary size i.e number of unique characters in the Dataset\n",
        "print(idx2char)\n",
        "print(vocal_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctp7SVQPrKxd",
        "outputId": "eca662f5-5d2c-4894-ea93-004647b2cb3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n",
            "{0: '.', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the Dataset\n",
        "block_size = 3 # Context Length i.e the number of characters it will remember and use in predicting the next character\n",
        "\n",
        "def dataset(names):\n",
        "\n",
        "  X, y = [], [] # X stores values of the Context and y stores the character which should come next based on that context\n",
        "\n",
        "  for name in names:\n",
        "    context = [0] * block_size # Setting Initial Context as Zero Padded Vector\n",
        "    for char in name + '.' :\n",
        "      idx = char2idx[char]\n",
        "      X.append(context) # Storing context to X\n",
        "      y.append(idx) # Storing Char to y\n",
        "      context = context[1:] + [idx] # New Context\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  y = torch.tensor(y)\n",
        "  print(X.shape, y.shape)\n",
        "  return X, y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(names)\n",
        "n1 = int(0.8 * len(names))\n",
        "n2 = int(0.9 * len(names))\n",
        "\n",
        "Xtrain, ytrain = dataset(names[ : n1]) # 80% training data\n",
        "Xval, yval = dataset(names[n1 : n2]) # 10% validation data\n",
        "Xtest, ytest = dataset(names[n2 : ]) # 10% testing data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjpc2u-NsiCJ",
        "outputId": "c4b5c992-de35-4b50-86ef-fd8a62d23fc5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([395805, 3]) torch.Size([395805])\n",
            "torch.Size([49490, 3]) torch.Size([49490])\n",
            "torch.Size([49352, 3]) torch.Size([49352])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility Function For Comparing Manual Gradients with PyTorch Gradients\n",
        "def compare(s, dt, t):\n",
        "  exact = torch.all(dt == t.grad).item() # Comparing if both are exactly equal or not\n",
        "  approx = torch.allclose(dt, t.grad) # Comparing if both are approximatelty equal or not\n",
        "  maxdiff = (dt - t.grad).abs().max().item() # finding the max difference in both\n",
        "  print(f'{s:15s} | exact: {str(exact):5s} | approximate: {str(approx):5s} | maxdiff: {maxdiff}')"
      ],
      "metadata": {
        "id": "CW9nY-YtxdT8"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # Dimentionality of the character embedding Vector\n",
        "n_hidden = 64 # Number of Neurons in the hidden layer of MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(42) # For Reproducibility\n",
        "C = torch.randn((vocal_size, n_embd), generator=g)\n",
        "\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3) / ((n_embd * block_size) ** 0.5) # It is a weight initialization technique know as Gaussian Init\n",
        "b1 = torch.randn(n_hidden, generator=g) * 0.1 # It is of no use because of Batch Normalization but is used just for fun\n",
        "\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocal_size), generator=g) * 0.1\n",
        "b2 = torch.randn(vocal_size, generator=g) * 0.1\n",
        "\n",
        "# BatchNorm Parameters\n",
        "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
        "\n",
        "# Parameters\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # Number of Parameters in Total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "LbrgeZpSymju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a440198-2083-45f1-dc7f-18b9828584e7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constructing a mini-batch\n",
        "batch_size = n = 32\n",
        "idx = torch.randint(0, Xtrain.shape[0], (batch_size,), generator=g)\n",
        "Xbatch, ybatch = Xtrain[idx], ytrain[idx]"
      ],
      "metadata": {
        "id": "WQV7tax-2j4L"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass\n",
        "\n",
        "emb = C[Xbatch] # Embedded the characters into vectors\n",
        "embcat = emb.view(emb.shape[0], -1) # Concatenate the vectors\n",
        "\n",
        "# Linear Layer 1\n",
        "hprebn = embcat @ W1 + b1 # Hidden Layer Before Batch Norm i.e pre-batchnorm\n",
        "\n",
        "# BatchNorm Layer\n",
        "bnmeani = 1/n * hprebn.sum(0, keepdim=True) # Xbar\n",
        "bndiff = hprebn - bnmeani # X - Xbar\n",
        "bndiff2 = bndiff ** 2 # (X -Xbar) ^ 2\n",
        "bnvar = 1/(n-1) * bndiff2.sum(0, keepdim=True) # Bessel's Correction Dividing by (n-1) not n for better variance i.e 1/(n-1) * sigma((X - Xbar) ^ 2)\n",
        "bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# adding Non-Linearity by using Activation Function\n",
        "h = torch.tanh(hpreact)\n",
        "\n",
        "# Linear Layer 2\n",
        "logits = h @ W2 + b2\n",
        "\n",
        "# Cross Entropy Loss (Same as F.cross_entropy(logits, ybatch))\n",
        "logit_maxes = logits.max(1, keepdim=True).values\n",
        "norm_logits = logits - logit_maxes # Substracting max logits value from all logits to provide stability\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum ** -1\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), ybatch].mean()\n",
        "\n",
        "# PyTorch Backward Pass\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybhWWKMT3NU3",
        "outputId": "26472547-4245-4228-a1ed-725e00b3aa35"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3946, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BackPropogating Through the Whole Thing Manually"
      ],
      "metadata": {
        "id": "VdGNDJ1zZLlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "varlist = [\n",
        "    ('logprobs', logprobs),\n",
        "    ('probs', probs),\n",
        "    ('counts_sum_inv', counts_sum_inv),\n",
        "    ('counts_sum', counts_sum),\n",
        "    ('counts', counts),\n",
        "    ('norm_logits', norm_logits),\n",
        "    ('logit_maxes', logit_maxes),\n",
        "    ('logits', logits),\n",
        "    ('h', h),\n",
        "    ('W2', W2),\n",
        "    ('b2', b2),\n",
        "    ('hpreact', hpreact),\n",
        "    ('bngain', bngain),\n",
        "    ('bnbias', bnbias),\n",
        "    ('bnraw', bnraw),\n",
        "    ('bnvar_inv', bnvar_inv),\n",
        "    ('bnvar', bnvar),\n",
        "    ('bndiff2', bndiff2),\n",
        "    ('bndiff', bndiff),\n",
        "    ('bnmeani', bnmeani),\n",
        "    ('hprebn', hprebn),\n",
        "    ('embcat', embcat),\n",
        "    ('W1', W1),\n",
        "    ('b1', b1),\n",
        "    ('emb', emb),\n",
        "    ('C', C),\n",
        "]\n",
        "\n",
        "for name, tensor in varlist:\n",
        "    print(f'{name}.shape = {tensor.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9PujLoiaOVy",
        "outputId": "343f2cd2-2f79-4a1e-fcd9-17ce37fed60f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs.shape = torch.Size([32, 27])\n",
            "probs.shape = torch.Size([32, 27])\n",
            "counts_sum_inv.shape = torch.Size([32, 1])\n",
            "counts_sum.shape = torch.Size([32, 1])\n",
            "counts.shape = torch.Size([32, 27])\n",
            "norm_logits.shape = torch.Size([32, 27])\n",
            "logit_maxes.shape = torch.Size([32, 1])\n",
            "logits.shape = torch.Size([32, 27])\n",
            "h.shape = torch.Size([32, 64])\n",
            "W2.shape = torch.Size([64, 27])\n",
            "b2.shape = torch.Size([27])\n",
            "hpreact.shape = torch.Size([32, 64])\n",
            "bngain.shape = torch.Size([1, 64])\n",
            "bnbias.shape = torch.Size([1, 64])\n",
            "bnraw.shape = torch.Size([32, 64])\n",
            "bnvar_inv.shape = torch.Size([1, 64])\n",
            "bnvar.shape = torch.Size([1, 64])\n",
            "bndiff2.shape = torch.Size([32, 64])\n",
            "bndiff.shape = torch.Size([32, 64])\n",
            "bnmeani.shape = torch.Size([1, 64])\n",
            "hprebn.shape = torch.Size([32, 64])\n",
            "embcat.shape = torch.Size([32, 30])\n",
            "W1.shape = torch.Size([30, 64])\n",
            "b1.shape = torch.Size([64])\n",
            "emb.shape = torch.Size([32, 3, 10])\n",
            "C.shape = torch.Size([27, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy Loss\n",
        "\n",
        "# 1. logit_maxes = logits.max(1, keepdims=True).values\n",
        "# 2. norm_logits = logits - logit_maxes # Substracting max logits value from all logits to provide stability\n",
        "# 3. counts = norm_logits.exp()\n",
        "# 4. counts_sum = counts.sum(1, keepdims=True)\n",
        "# 5. counts_sum_inv = counts_sum ** -1\n",
        "# 6. probs = counts * counts_sum_inv\n",
        "# 7. logprobs = probs.log()\n",
        "# 8. loss = -logprobs[range(n), ybatch].mean()\n",
        "\n",
        "dlogprobs = torch.zeros_like(logprobs) # Making matrics of same shape as logprobs\n",
        "dlogprobs[range(n), ybatch] = -1.0/n # Diff logprobs in 8\n",
        "dprobs = (1.0 / probs) * dlogprobs # diff probs in 7\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True) # Diff counts_sum_inv in 6\n",
        "dcounts = counts_sum_inv * dprobs # Diff counts in 6\n",
        "dcounts_sum = (-counts_sum ** -2) * dcounts_sum_inv # Diff counts_sum in 5\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum # Diff counts in 4 and adding it with previous dcounts value from 6\n",
        "dnorm_logits = counts * dcounts # Diff norm_logits in 3\n",
        "dlogits = dnorm_logits.clone() # Diff logits in 2 it comes out to be same as dnorm_logits\n",
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True) # Diff logit_maxes in 2\n",
        "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes # Diff logits in 1 and adding it with previous dlogits from 2\n",
        "\n",
        "# Comparing Manual Gradients with PyTorch Gradients\n",
        "\n",
        "compare('logprobs', dlogprobs, logprobs)\n",
        "compare('probs', dprobs, probs)\n",
        "compare('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare('counts_sum', dcounts_sum, counts_sum)\n",
        "compare('counts', dcounts, counts)\n",
        "compare('norm_logits', dnorm_logits, norm_logits)\n",
        "compare('logit_maxes', dlogit_maxes, logit_maxes)\n",
        "compare('logits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_n86C2mUOb2",
        "outputId": "edc95021-59a2-42b3-d17d-7a3d2f228234"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Layer 2\n",
        "\n",
        "# 1. logits = h @ W2 + b2\n",
        "\n",
        "dh = dlogits @ W2.T # Diff h in 1 keep in mind the shapes\n",
        "dW2 = h.T @ dlogits # Diff W2 in 1 keep in mind the shapes\n",
        "db2 = dlogits.sum(0) # Diff b2 in 1 and keep in mind the shapes\n",
        "\n",
        "# Comparing Manual Gradients with PyTorch Gradients\n",
        "\n",
        "compare('h', dh, h)\n",
        "compare('W2', dW2, W2)\n",
        "compare('b2', db2, b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1hRqgBTZA75",
        "outputId": "36018113-3795-4f14-db56-06879b79e0f8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Differentiation of Tanh (Activation Function)\n",
        "\n",
        "# 1. h = torch.tanh(hpreact)\n",
        "\n",
        "dhpreact = (1.0 - h ** 2) * dh # Diff Tan(X) = 1 - Tan^2(X)\n",
        "\n",
        "# Comparing Manual Gradients with PyTorch Gradients\n",
        "\n",
        "compare('hpreact', dhpreact, hpreact) # Exactly They are not equal due to Floating Point Precision but this small difference can be neglected here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPylGlXEm-5H",
        "outputId": "eb67ccf3-e3af-42ca-8d57-bc888ee8ab4e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BatchNorm Layer\n",
        "\n",
        "# 1. bnmeani = 1/n * hprebn.sum(0, keepdim=True) # Xbar\n",
        "# 2. bndiff = hprebn - bnmeani # X - Xbar\n",
        "# 3. bndiff2 = bndiff ** 2 # (X -Xbar) ^ 2\n",
        "# 4. bnvar = 1/(n-1) * bndiff2.sum(0, keepdim=True) # Bessel's Correction Dividing by (n-1) not n for better variance i.e 1/(n-1) * sigma((X - Xbar) ^ 2)\n",
        "# 5. bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
        "# 6. bnraw = bndiff * bnvar_inv\n",
        "# 7. hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "dbngain = (bnraw * dhpreact).sum(0, keepdim=True) # Diff bngain in 7 and keeping dim same\n",
        "dbnraw = bngain * dhpreact # Diff bnraw in 7\n",
        "dbnbias = dhpreact.sum(0, keepdim=True) # Diff bnbias in 7 and making same shape\n",
        "dbndiff = bnvar_inv * dbnraw # Diff bndiff in 6\n",
        "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True) # Diff bnvar_inv in 6 and making similar shape\n",
        "dbnvar = (-0.5 * (bnvar + 1e-5) ** -1.5) * dbnvar_inv # Diff bnvar in 5\n",
        "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar # Diff dbndiff2 in 4\n",
        "dbndiff += (2 * bndiff) * dbndiff2 # Diff bndiff in 3 and adding it with previous dbndiff from 6\n",
        "dhprebn = dbndiff.clone() # Diff hprebn in 2\n",
        "dbnmeani = (-dbndiff).sum(0) # Diff bnmeani in 2\n",
        "dhprebn += (1.0/n) * (torch.ones_like(hprebn) * dbnmeani) # Diff hprebn in 1 and adding it with previous dhprebn from 2\n",
        "\n",
        "# Comparing Manual Gradients with PyTorch Gradients\n",
        "\n",
        "compare('bngain', dbngain, bngain)\n",
        "compare('bnbias', dbnbias, bnbias)\n",
        "compare('bnraw', dbnraw, bnraw)\n",
        "compare('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "compare('bnvar', dbnvar, bnvar)\n",
        "compare('bndiff2', dbndiff2, bndiff2)\n",
        "compare('bndiff', dbndiff, bndiff)\n",
        "compare('bnmeani', dbnmeani, bnmeani)\n",
        "compare('hprebn', dhprebn, hprebn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk7JAKj1n0Qe",
        "outputId": "4267b913-a8cd-4951-988e-a4d365d106b6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "bnbias          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnraw           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
            "bnvar           | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "bndiff2         | exact: False | approximate: True  | maxdiff: 2.1827872842550278e-11\n",
            "bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bnmeani         | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
            "hprebn          | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Layer 1\n",
        "\n",
        "# 1. hprebn = embcat @ W1 + b1\n",
        "\n",
        "dembcat = dhprebn @ W1.T # Diff embcat in 1\n",
        "dW1 = embcat.T @ dhprebn # Diff W1 in 1\n",
        "db1 = dhprebn.sum(0)\n",
        "\n",
        "# Comparing Manual Gradients with PyTorch Gradients\n",
        "\n",
        "compare('embcat', dembcat, embcat)\n",
        "compare('W1', dW1, W1)\n",
        "compare('b1', db1, b1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nfgD6McuEf2",
        "outputId": "26bf314b-ff85-40d0-b875-3d037daae50f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embcat          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "W1              | exact: False | approximate: True  | maxdiff: 1.0011717677116394e-08\n",
            "b1              | exact: False | approximate: True  | maxdiff: 6.752088665962219e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding Layer\n",
        "\n",
        "# 1. emb = C[Xbatch] # Embedded the characters into vectors\n",
        "# 2. embcat = emb.view(emb.shape[0], -1) # Concatenate the vectors\n",
        "\n",
        "demb = dembcat.view(emb.shape) # Diff emb in 2\n",
        "dC = torch.zeros_like(C) # Diff C in 1\n",
        "for k in range(Xbatch.shape[0]):\n",
        "  for j in range(Xbatch.shape[1]):\n",
        "    idx = Xbatch[k, j]\n",
        "    dC[idx] += demb[k, j]\n",
        "\n",
        "# Comparing Manual Gradients with PyTorch Gradients\n",
        "\n",
        "compare('emb', demb, emb)\n",
        "compare('C', dC, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XYr1_u4u_pR",
        "outputId": "82da87c3-d2ed-4355-d0b0-fff3f0428f8e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emb             | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "C               | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BackPropogating in 1 Go"
      ],
      "metadata": {
        "id": "g-RQbzYX4pjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# logit_maxes = logits.max(1, keepdim=True).values\n",
        "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# Now:\n",
        "new_loss = F.cross_entropy(logits, ybatch)\n",
        "print(new_loss.item(), 'diff:', (new_loss - loss).item())\n",
        "\n",
        "# Backward Pass\n",
        "\n",
        "dlogits = None\n",
        "dlogits = F.softmax(logits, 1)\n",
        "dlogits[range(n), ybatch] -= 1\n",
        "dlogits /= n\n",
        "\n",
        "compare('logits', dlogits, logits) # Very Minimal Difference so we can neglect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxYqH9GM2ZrW",
        "outputId": "2a41fdf2-acdc-4c1c-b7a3-192fbdeec64f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3945655822753906 diff: 0.0\n",
            "logits          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch Norm\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "# bndiff = hprebn - bnmeani\n",
        "# bndiff2 = bndiff**2\n",
        "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "# bnraw = bndiff * bnvar_inv\n",
        "# hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# Now:\n",
        "new_hpreact = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias # unbiased hyperparameter represents that we keep bessel's correction in mind and it will divide by (n-1) instead of n\n",
        "print('max diff:', (new_hpreact - hpreact).abs().max())\n",
        "\n",
        "# Backward Pass\n",
        "dhprebn = bngain * bnvar_inv / n * (n * dhpreact - dhpreact.sum(0) - n/(n-1) * bnraw * (dhpreact * bnraw).sum(0))\n",
        "compare('hprebn', dhprebn, hprebn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpDrg2G749OU",
        "outputId": "f754bba7-da5d-4545-add2-2c860fd60bab"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n",
            "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training MLP From Scratch"
      ],
      "metadata": {
        "id": "AjHx6B_W8PXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # Dimentionality of the character embedding Vector\n",
        "n_hidden = 64 # Number of Neurons in the hidden layer of MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(42) # For Reproducibility\n",
        "C = torch.randn((vocal_size, n_embd), generator=g)\n",
        "\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3) / ((n_embd * block_size) ** 0.5) # It is a weight initialization technique know as Gaussian Init\n",
        "b1 = torch.randn(n_hidden, generator=g) * 0.1 # It is of no use because of Batch Normalization but is used just for fun\n",
        "\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocal_size), generator=g) * 0.1\n",
        "b2 = torch.randn(vocal_size, generator=g) * 0.1\n",
        "\n",
        "# BatchNorm Parameters\n",
        "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
        "\n",
        "# Parameters\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # Number of Parameters in Total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True\n",
        "\n",
        "# Optimization\n",
        "max_steps = 60000\n",
        "batch_size = 512\n",
        "n = batch_size\n",
        "lossi = []\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  # Starting Optimization\n",
        "  for i in range(max_steps):\n",
        "\n",
        "    # Constructing a mini-batch\n",
        "    batch_size = n = 32\n",
        "    idx = torch.randint(0, Xtrain.shape[0], (batch_size,), generator=g)\n",
        "    Xbatch, ybatch = Xtrain[idx], ytrain[idx]\n",
        "\n",
        "    # Forward Pass\n",
        "\n",
        "    emb = C[Xbatch] # Embedded the characters into vectors\n",
        "    embcat = emb.view(emb.shape[0], -1) # Concatenate the vectors\n",
        "\n",
        "    # Linear Layer 1\n",
        "    hprebn = embcat @ W1 + b1 # Hidden Layer Before Batch Norm i.e pre-batchnorm\n",
        "\n",
        "    # BatchNorm Layer\n",
        "    bnmeani = 1/n * hprebn.sum(0, keepdim=True) # Xbar\n",
        "    bndiff = hprebn - bnmeani # X - Xbar\n",
        "    bndiff2 = bndiff ** 2 # (X -Xbar) ^ 2\n",
        "    bnvar = 1/(n-1) * bndiff2.sum(0, keepdim=True) # Bessel's Correction Dividing by (n-1) not n for better variance i.e 1/(n-1) * sigma((X - Xbar) ^ 2)\n",
        "    bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
        "    bnraw = bndiff * bnvar_inv\n",
        "    hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "    # adding Non-Linearity by using Activation Function\n",
        "    h = torch.tanh(hpreact)\n",
        "\n",
        "    # Linear Layer 2\n",
        "    logits = h @ W2 + b2\n",
        "\n",
        "    # Cross Entropy Loss (Same as F.cross_entropy(logits, ybatch))\n",
        "    logit_maxes = logits.max(1, keepdim=True).values\n",
        "    norm_logits = logits - logit_maxes # Substracting max logits value from all logits to provide stability\n",
        "    counts = norm_logits.exp()\n",
        "    counts_sum = counts.sum(1, keepdims=True)\n",
        "    counts_sum_inv = counts_sum ** -1\n",
        "    probs = counts * counts_sum_inv\n",
        "    logprobs = probs.log()\n",
        "    loss = -logprobs[range(n), ybatch].mean()\n",
        "\n",
        "    # PyTorch Backward Pass\n",
        "    for p in parameters:\n",
        "      p.grad = None\n",
        "      # loss.backward()\n",
        "\n",
        "    # Manual BackProp\n",
        "\n",
        "    # Cross Entropy Loss\n",
        "    dlogits = F.softmax(logits, 1)\n",
        "    dlogits[range(n), ybatch] -= 1\n",
        "    dlogits /= n\n",
        "\n",
        "    # Linear Layer 2\n",
        "    dh = dlogits @ W2.T\n",
        "    dW2 = h.T @ dlogits\n",
        "    db2 = dlogits.sum(0)\n",
        "\n",
        "    # Activation Function Tanh\n",
        "    dhpreact = (1.0 - h ** 2) * dh\n",
        "\n",
        "    # BatchNorm BackProp\n",
        "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
        "    dhprebn = bngain * bnvar_inv / n * (n * dhpreact - dhpreact.sum(0) - n/(n-1) * bnraw * (dhpreact * bnraw).sum(0))\n",
        "\n",
        "    # Linear Layer 1\n",
        "    dembcat = dhprebn @ W1.T\n",
        "    dW1 = embcat.T @ dhprebn\n",
        "    db1 = dhprebn.sum(0)\n",
        "\n",
        "    # Embedding Layer\n",
        "    demb = dembcat.view(emb.shape)\n",
        "    dC = torch.zeros_like(C)\n",
        "    for k in range(Xbatch.shape[0]):\n",
        "      for j in range(Xbatch.shape[1]):\n",
        "        idx = Xbatch[k, j]\n",
        "        dC[idx] += demb[k, j]\n",
        "\n",
        "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "\n",
        "    # Update\n",
        "    lr = 0.5 if i<20000 else 0.01\n",
        "    for p, grad in zip(parameters, grads):\n",
        "      # p.data += -lr * p.grad  # Old way used in (loss.backward())\n",
        "      p.data += -lr * grad # New Way used in manual Backprop\n",
        "\n",
        "    # track stats\n",
        "    if i % 10000 == 0: # print every once in a while\n",
        "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "    lossi.append(loss.log10().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg7e5_Oq6yuP",
        "outputId": "26d9ed43-962c-4e70-9afc-87aa09619175"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4137\n",
            "      0/  60000: 3.4107\n",
            "  10000/  60000: 1.8082\n",
            "  20000/  60000: 2.1200\n",
            "  30000/  60000: 1.7357\n",
            "  40000/  60000: 2.2835\n",
            "  50000/  60000: 1.7885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calibrate the batch norm at the end of training\n",
        "\n",
        "with torch.no_grad():\n",
        "  # pass the training set through\n",
        "  emb = C[Xtrain]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  # measure the mean/std over the entire training set\n",
        "  bnmean = hpreact.mean(0, keepdim=True)\n",
        "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
      ],
      "metadata": {
        "id": "Jxqo1jmZAqS7"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate train and val loss\n",
        "\n",
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtrain, ytrain),\n",
        "    'val': (Xval, yval),\n",
        "    'test': (Xtest, ytest),\n",
        "  }[split]\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21hG5jlLBKnP",
        "outputId": "6593b734-33a1-4a27-eb09-c782060d25b1"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 1.9334039688110352\n",
            "val 1.9393078088760376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating Some Names\n",
        "def generate_names(number):\n",
        "\n",
        "  out =[]\n",
        "  for _ in range(number):\n",
        "\n",
        "    context = [0] * block_size\n",
        "    name = ''\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "      hpreact = embcat @ W1 + b1\n",
        "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "      logits = h @ W2 + b2 # (N, vocab_size)\n",
        "\n",
        "      probs = F.softmax(logits, dim = 1)\n",
        "      idx = torch.multinomial(probs, num_samples=1).item()\n",
        "      context = context[1:] + [idx]\n",
        "      if idx == 0:\n",
        "        break\n",
        "      name += (idx2char[idx])\n",
        "    out.append(name)\n",
        "  return out\n"
      ],
      "metadata": {
        "id": "xWMdur2pCnxQ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_names(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c-DZkTVDKoL",
        "outputId": "7edb2d64-47e6-4587-df87-07aa406b8c25"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['div',\n",
              " 'dh',\n",
              " 'shinesh',\n",
              " 'shgino',\n",
              " 'n',\n",
              " 's',\n",
              " 'el',\n",
              " 'v',\n",
              " 'ni',\n",
              " 'muth',\n",
              " 'enth',\n",
              " 's',\n",
              " 's',\n",
              " 'koh',\n",
              " 'il']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKYOMLi3Bsta"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}